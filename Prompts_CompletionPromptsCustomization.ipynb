{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Completion Prompts Customization](https://docs.llamaindex.ai/en/stable/examples/customization/prompts/completion_prompts/#completion-prompts-customization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: GPU\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-small-en\n",
      "Load pretrained SentenceTransformer: BAAI/bge-small-en\n",
      "Load pretrained SentenceTransformer: BAAI/bge-small-en\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "MIXTRAL_TEXT_GENERATION_MODEL_REPO = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "print(\"DEVICE:\", \"GPU\" if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import (\n",
    "    HuggingFaceEmbedding,\n",
    ")\n",
    "from llama_index.llms.huggingface import HuggingFaceInferenceAPI\n",
    "\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(cache_folder=\"./tmp/models/\")\n",
    "\n",
    "Settings.llm = HuggingFaceInferenceAPI(\n",
    "    tokenizer_name=MIXTRAL_TEXT_GENERATION_MODEL_REPO,\n",
    "    model_name=MIXTRAL_TEXT_GENERATION_MODEL_REPO,\n",
    "    device_map=\"sequential\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "text_qa_template_str = (\n",
    "    \"Context information is\"\n",
    "    \" below.\\n---------------------\\n{context_str}\\n---------------------\\nUsing\"\n",
    "    \" both the context information and also using your own knowledge, answer\"\n",
    "    \" the question: {query_str}\\nIf the context isn't helpful, you can also\"\n",
    "    \" answer the question on your own.\\n\"\n",
    ")\n",
    "text_qa_template = PromptTemplate(text_qa_template_str)\n",
    "\n",
    "refine_template_str = (\n",
    "    \"The original question is as follows: {query_str}\\nWe have provided an\"\n",
    "    \" existing answer: {existing_answer}\\nWe have the opportunity to refine\"\n",
    "    \" the existing answer (only if needed) with some more context\"\n",
    "    \" below.\\n------------\\n{context_msg}\\n------------\\nUsing both the new\"\n",
    "    \" context and your own knowledge, update or repeat the existing answer.\\n\"\n",
    ")\n",
    "refine_template = PromptTemplate(refine_template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data/test/\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iris is a wild flower found in the Himalayas from the west to the east, growing at heights of 2800-4000 m. on open slopes and grazing grounds. It has one of the loveliest names of all flowers and is characterized by its bright lilac-purple flowers with yellow-tipped beards or combs on the outer petals. The iris grows from an underground rhizome and likes wet ground. There are more than a dozen varieties of iris in the mountains, including I. germanica or Keor eka-mul, which is cultivated in the hills for orris oil, and I. nepalensis, or Chiluchi, whose roots are used in medicines as a diuretic and for bilious complaints.\n"
     ]
    }
   ],
   "source": [
    "print(index.as_query_engine().query(\"what is iris?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 21.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To write in Gujarati language, you can use a Gujarati keyboard or a word processor with Gujarati language support. You can also use a virtual keyboard or a transliteration tool to type Gujarati characters using the English alphabet. Additionally, there are several Gujarati fonts available that you can use to write in Gujarati. It is important to note that Gujarati is written from right to left, unlike English which is written from left to right. Therefore, you will need to adjust your writing direction accordingly.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    index.as_query_engine(\n",
    "        text_qa_template=text_qa_template,\n",
    "        refine_template=refine_template,\n",
    "    ).query(\"how to write in gujarati language ?\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
